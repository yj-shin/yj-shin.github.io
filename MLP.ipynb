{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP.ipynb",
      "provenance": [],
      "mount_file_id": "1-iRVLsc8DcySYGhw_h0mB1UEsQC87TpQ",
      "authorship_tag": "ABX9TyNHgNiEUoCE6FbPTLQWBQ94",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yj-shin/yj-shin.github.io/blob/master/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VoWNohOBfiE"
      },
      "source": [
        "# Load relevant libraries\n",
        "\n",
        "# numpy 행렬 등 수학적 처리 모듈 \n",
        "# pandas 데이터 처리 및 조작 모듈\n",
        "# seaborn: 시각화\n",
        "# matplotlib : 그래프\n",
        "# python : 언어\n",
        "# missingno : 누락된 값을 한눈에 볼 수 있음\n",
        "# sklearn : ML 알고리즘 라이브러리\n",
        "# csv 파일을 import하여 dataset이 pandas dataframe이 되도록 한다\n",
        "# CSV : Comma Separated Values 쉼표로 구분된 값의 약어로 테이블 형식의 데이터를 표현하고 저장하는 일반적인 방법\n",
        "\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "#from keras.models import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yNNPtkOBF6C"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/test/MiningProcess_Flotation_Plant_Database.csv\",decimal=\",\",parse_dates=[\"date\"],infer_datetime_format=True).drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFWhPaV5BpCM",
        "outputId": "3284e31c-dff3-48b2-dc97-9b16cdd66e45"
      },
      "source": [
        "# Resample data to hourly basis\n",
        "df = df.set_index('date').resample('H').first()\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4415, 23)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCOzgHCqH3QC",
        "outputId": "51dc4ef1-0f2e-4d5f-9921-76ac1995a263"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "% Iron Feed                     318\n",
              "% Silica Feed                   318\n",
              "Starch Flow                     318\n",
              "Amina Flow                      318\n",
              "Ore Pulp Flow                   318\n",
              "Ore Pulp pH                     318\n",
              "Ore Pulp Density                318\n",
              "Flotation Column 01 Air Flow    318\n",
              "Flotation Column 02 Air Flow    318\n",
              "Flotation Column 03 Air Flow    318\n",
              "Flotation Column 04 Air Flow    318\n",
              "Flotation Column 05 Air Flow    318\n",
              "Flotation Column 06 Air Flow    318\n",
              "Flotation Column 07 Air Flow    318\n",
              "Flotation Column 01 Level       318\n",
              "Flotation Column 02 Level       318\n",
              "Flotation Column 03 Level       318\n",
              "Flotation Column 04 Level       318\n",
              "Flotation Column 05 Level       318\n",
              "Flotation Column 06 Level       318\n",
              "Flotation Column 07 Level       318\n",
              "% Iron Concentrate              318\n",
              "% Silica Concentrate            318\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHFbX0PaHchu"
      },
      "source": [
        "#for column in df.columns:\n",
        "#   df[column] = df[column].apply(lambda x: x.replace(',', '.'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tZA9ckxCBMo",
        "outputId": "fae9aff1-dc68-47c9-ecac-0ec36d7484c0"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "target = '% Silica Concentrate'\n",
        "\n",
        "y = df[target]\n",
        "\n",
        "X_n = df.drop([target, '% Iron Concentrate'], axis=1) \n",
        "X_i = df.drop(target, axis=1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_n = scaler.fit_transform(X_n)\n",
        "X_i = scaler.fit_transform(X_i)\n",
        "\n",
        "X_n_train, X_n_test, y_n_train, y_n_test = train_test_split(X_n, y, train_size=0.7)\n",
        "X_i_train, X_i_test, y_i_train, y_i_test = train_test_split(X_i, y, train_size=0.7)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()   # 객체 만들기\n",
        "scaler.fit(x_train)     # 변환 규칙을 익히기\n",
        "x_train_scaled = scaler.transform(x_train)  # 데이터를 표준화 전처리\n",
        "x_val_scaled = scaler.transform(x_val)      # 데이터를 표준화 전처리\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10,), activation='logistic', \\\n",
        "                    solver='sgd', alpha=0.01, batch_size=32, \\\n",
        "                    learning_rate_init=0.1, max_iter=500)  # 객체 생성\n",
        "\n",
        "mlp.fit(x_train_scaled, y_train)    # 훈련하기\n",
        "mlp.score(x_val_scaled, y_val)      # 정확도 평가"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.978021978021978"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}